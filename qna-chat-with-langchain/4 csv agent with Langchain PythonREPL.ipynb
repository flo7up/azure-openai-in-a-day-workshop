{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CSV agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Load environment variables (set OPENAI_API_KEY and OPENAI_API_BASE in .env)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    "openai.api_base = os.getenv('OPENAI_API_ENDPOINT')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI model\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt4o\",  # replace with your deployment name\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")\n",
    "\n",
    "# Define the web_search tool\n",
    "search = TavilySearchResults(max_results=2)\n",
    "# Define the Python code execution tool\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")\n",
    "\n",
    "# Create the agent with memory and tools\n",
    "tools = [search, repl_tool]\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)\n",
    "\n",
    "# Configuration for conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent response\n",
      "\n",
      "tool response\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "\n",
      "agent response\n",
      "The Titanic dataset has been successfully loaded into a pandas DataFrame. Here are the first five rows:\n",
      "\n",
      "|   | PassengerId | Survived | Pclass | Name                                      | Sex    | Age  | SibSp | Parch | Ticket  | Fare    | Cabin | Embarked |\n",
      "|---|-------------|----------|--------|-------------------------------------------|--------|------|-------|-------|---------|---------|-------|----------|\n",
      "| 0 | 892         | 0        |\n"
     ]
    }
   ],
   "source": [
    "# # testing the agent with a few messages\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"load the titanic.csv into a pandas dataframe\")]}, config\n",
    "):   \n",
    "        #print(chunk)\n",
    "        try:\n",
    "            if 'agent' in chunk:\n",
    "                messages = chunk['agent']['messages'][0].content\n",
    "                print('agent response')\n",
    "                print(messages)\n",
    "            elif 'tools' in chunk:\n",
    "                messages = chunk['tools']['messages'][0].content\n",
    "                print('tool response')\n",
    "                print(messages)\n",
    "            else:\n",
    "                messages = []\n",
    "        except KeyError:\n",
    "            print(\"KeyError\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'agent_executor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ask follow up questions\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[43magent_executor\u001b[49m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      3\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m: [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhow many rows are there in the titanic.csv?\u001b[39m\u001b[38;5;124m\"\u001b[39m)]}, config\n\u001b[0;32m      4\u001b[0m ):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#print(chunk)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magent\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m chunk:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'agent_executor' is not defined"
     ]
    }
   ],
   "source": [
    "# ask follow up questions\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"how many rows are there in the titanic.csv?\")]}, config\n",
    "):\n",
    "    #print(chunk)\n",
    "        try:\n",
    "            if 'agent' in chunk:\n",
    "                messages = chunk['agent']['messages'][0].content\n",
    "                print('agent response')\n",
    "                print(messages)\n",
    "            elif 'tools' in chunk:\n",
    "                print(chunk)\n",
    "                messages = chunk['tools']['messages'][0].content\n",
    "                print('tool response')\n",
    "                print(messages)\n",
    "            else:\n",
    "                messages = []\n",
    "        except KeyError:\n",
    "            print(\"KeyError\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basiclc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
