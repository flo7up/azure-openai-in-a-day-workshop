{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a CSV agent\n",
    "By themselves, language models can't take actions - they just output text. A big use case for LangChain is creating agents. \n",
    "Agents are systems that use an LLM as a reasoning enginer to determine which actions to take and what the inputs to those actions should be. \n",
    "The results of those actions can then be fed back into the agent and it determine whether more actions are needed, or whether it is okay to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant functionality\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "# Load environment variables (set OPENAI_API_KEY and OPENAI_API_BASE in .env)\n",
    "load_dotenv()\n",
    "\n",
    "# Configure Azure OpenAI Service API\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_version = os.getenv(\"AZURE_OPENAI_VERSION\")\n",
    "openai.api_base = os.getenv('OPENAI_API_ENDPOINT')\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Azure OpenAI model\n",
    "llm = AzureChatOpenAI(\n",
    "    deployment_name=\"gpt4o\",  # replace with your deployment name\n",
    "    temperature=0.5,\n",
    "    max_tokens=100,\n",
    "    openai_api_version=\"2023-03-15-preview\"\n",
    ")\n",
    "\n",
    "# Define the web_search tool\n",
    "search = TavilySearchResults(max_results=2)\n",
    "# Define the Python code execution tool\n",
    "python_repl = PythonREPL()\n",
    "repl_tool = Tool(\n",
    "    name=\"python_repl\",\n",
    "    description=\"A Python shell. Use this to execute python commands. Input should be a valid python command. If you want to see the output of a value, you should print it out with `print(...)`.\",\n",
    "    func=python_repl.run,\n",
    ")\n",
    "\n",
    "\n",
    "# Create the agent with memory and tools\n",
    "tools = [search, repl_tool]\n",
    "memory = SqliteSaver.from_conn_string(\":memory:\")\n",
    "agent_executor = create_react_agent(llm, tools, checkpointer=memory)\n",
    "\n",
    "# Configuration for conversation thread\n",
    "config = {\"configurable\": {\"thread_id\": \"abc123\"}}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent response\n",
      "\n",
      "tool response\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n",
      "\n",
      "agent response\n",
      "The Titanic dataset has been successfully loaded into a pandas DataFrame. Here are the first five rows:\n",
      "\n",
      "|   | PassengerId | Survived | Pclass | Name                                      | Sex    | Age  | SibSp | Parch | Ticket  | Fare    | Cabin | Embarked |\n",
      "|---|-------------|----------|--------|-------------------------------------------|--------|------|-------|-------|---------|---------|-------|----------|\n",
      "| 0 | 892         | 0        |\n"
     ]
    }
   ],
   "source": [
    "# # testing the agent with a few messages\n",
    "\n",
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"load the titanic.csv into a pandas dataframe\")]}, config\n",
    "):   \n",
    "        #print(chunk)\n",
    "        try:\n",
    "            if 'agent' in chunk:\n",
    "                messages = chunk['agent']['messages'][0].content\n",
    "                print('agent response')\n",
    "                print(messages)\n",
    "            elif 'tools' in chunk:\n",
    "                messages = chunk['tools']['messages'][0].content\n",
    "                print('tool response')\n",
    "                print(messages)\n",
    "            else:\n",
    "                messages = []\n",
    "        except KeyError:\n",
    "            print(\"KeyError\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agent response\n",
      "\n",
      "{'tools': {'messages': [ToolMessage(content='418\\n', name='python_repl', tool_call_id='call_ZtEsL7igpxTrdy4Z89xd2A4Y')]}}\n",
      "tool response\n",
      "418\n",
      "\n",
      "agent response\n",
      "The Titanic dataset contains 418 rows.\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent_executor.stream(\n",
    "    {\"messages\": [HumanMessage(content=\"how many rows are there in the titanic.csv?\")]}, config\n",
    "):\n",
    "    #print(chunk)\n",
    "        try:\n",
    "            if 'agent' in chunk:\n",
    "                messages = chunk['agent']['messages'][0].content\n",
    "                print('agent response')\n",
    "                print(messages)\n",
    "            elif 'tools' in chunk:\n",
    "                print(chunk)\n",
    "                messages = chunk['tools']['messages'][0].content\n",
    "                print('tool response')\n",
    "                print(messages)\n",
    "            else:\n",
    "                messages = []\n",
    "        except KeyError:\n",
    "            print(\"KeyError\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "basiclc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
